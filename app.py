import pickle
from pathlib import Path
from shutil import copyfile

import networkx as nx
from ipysigma import Sigma
from shinyswatch import theme
from shiny import reactive, req
from shiny.express import input, ui, render
from shinywidgets import render_widget, render_plotly
import pandas as pd
import netfunction
import plotly.express as px
from faicons import icon_svg
import plotly.graph_objects as go

from langchain_openai import ChatOpenAI
from langchain_community.document_loaders import DataFrameLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_huggingface import HuggingFaceEmbeddings

from rag_chat import create_qdrant_collection, create_vector_store, create_retrievers, format_docs, template

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
here = Path(__file__).parent
# –°–æ–∑–¥–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
temp_dir = here / "temp"
temp_dir.mkdir(exist_ok=True)

# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –±—É–¥–µ—Ç —Å—Ç—Ä–æ–∏—Ç—å—Å—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ temp_dir
vector_store_file = temp_dir / "vector_store.pkl"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
ui.page_opts(
    title=ui.div(
        icon_svg("vector-square"),      # –ò–∫–æ–Ω–∫–∞ —Å–µ—Ç–∏ –∏–∑ faicons
        " Network Dashboard",
        style="display: flex; align-items: center;"
    ),
    fillable=True,
    id="page",
    theme=theme.journal
)

# Sidebar: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –≥—Ä–∞—Ñ–æ–≤
with ui.sidebar(width=350):
    ui.HTML("<h5> ‚öôÔ∏è–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö</h5>")
    ui.hr()
    with ui.card(full_screen=False):
        ui.input_file("file", "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ:", accept=".xlsx", width=200,
                      button_label='–û–±–∑–æ—Ä', placeholder='–§–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')
    ui.hr()


@reactive.calc
def df():
    f = req(input.file())
    return pd.read_excel(f[0]['datapath'])


@reactive.calc
def processed_data():
    data = df()
    data['–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –Ω–∞–≤—ã–∫–∏'] = data['–ö–ª—é—á–µ–≤—ã–µ –Ω–∞–≤—ã–∫–∏'].apply(
        netfunction.parse_skills)
    data = data.dropna(subset=['–†–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å', '–ö–ª—é—á–µ–≤—ã–µ –Ω–∞–≤—ã–∫–∏'])
    data.reset_index(inplace=True, drop=True)
    data['–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏'] = pd.to_datetime(data['–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏'])
    data["–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥"] = data["–ù–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞"].apply(
        netfunction.get_federal_district)
    data['–î–∞–Ω–Ω—ã–µ'] = data.apply(lambda row:
                                f"{row['–†–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å']} –∏—â–µ—Ç "
                                f"{row['–ù–∞–∑–≤–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏']} —Å {row['–ö–ª—é—á–µ–≤—ã–µ –Ω–∞–≤—ã–∫–∏']}.", axis=1)
    return data


ui.nav_spacer()
with ui.nav_panel("–î–∞–Ω–Ω—ã–µ", icon=icon_svg("table")):
    with ui.card(full_screen=True):
        ui.card_header("üìñ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")

        @render.data_frame
        def table():
            return render.DataTable(processed_data(), filters=True, height='550px')

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ –∫–Ω–æ–ø–∫–∏ "–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ"
sample_set = set()  # –•—Ä–∞–Ω–∏–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –≤—ã–±–æ—Ä–∫–∏


@reactive.event(input.process_data)
def build_vector_store():
    data = processed_data()  # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame
    if data.empty:
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã —Ö—Ä–∞–Ω–∏–ª–∏—â–∞, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç
        for file in temp_dir.glob("vector_store_*.pkl"):
            file.unlink()
        return

    sample_size = input.sample_size()
    # –£–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ sample_size –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ temp_dir
    vector_store_file = temp_dir / f"vector_store_{sample_size}.pkl"

    # –ï—Å–ª–∏ –≤—ã–±–æ—Ä–∫–∞ —Å —Ç–∞–∫–∏–º sample_size —É–∂–µ –µ—Å—Ç—å, –∑–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    if vector_store_file.exists():
        with open(vector_store_file, "rb") as f:
            ensemble = pickle.load(f)
        print(
            f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è sample_size={sample_size}.")
        return ensemble

    sample_set.add(sample_size)
    # –§–æ—Ä–º–∏—Ä—É–µ–º –≤—ã–±–æ—Ä–∫—É –¥–∞–Ω–Ω—ã—Ö
    data_sample = data[['–ù–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞', '–î–∞–Ω–Ω—ã–µ', '–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã']].sample(
        sample_size, random_state=1)
    print("–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏:", data_sample.shape)

    loader = DataFrameLoader(data_sample, page_content_column="–î–∞–Ω–Ω—ã–µ")
    docs = loader.load()
    print("–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ:", len(docs))

    text_splitter = RecursiveCharacterTextSplitter()
    split_docs = text_splitter.split_documents(docs)
    print("–§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤:", len(split_docs))

    collection_name = 'navyk'
    client = create_qdrant_collection(collection_name=collection_name)
    vs = create_vector_store(client, collection_name, embeddings, split_docs)
    ensemble = create_retrievers(vs, split_docs)
    print(f"–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ–∑–¥–∞–Ω–æ –¥–ª—è sample_size={sample_size}.")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ temp_dir
    with open(vector_store_file, "wb") as f:
        pickle.dump(ensemble, f)
    print(f"–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {vector_store_file}")

    return ensemble


@reactive.effect
def update_models():
    if input.base_url() == "https://bothub.chat/api/v2/openai/v1":
        models = ["gpt-3.5-turbo", "gpt-4o", "gpt-4o-mini",
                  "o3-mini", "o1-mini"]
        ui.update_selectize("chat_model", choices=models)
    elif input.base_url() == "https://openrouter.ai/api/v1":
        models = ["google/gemini-2.0-flash-thinking-exp:free",
                  "deepseek/deepseek-chat:free",
                  "deepseek/deepseek-r1:free"]
        ui.update_selectize("chat_model", choices=models)


prompt = ChatPromptTemplate.from_template(template)

with ui.nav_panel("–ß–∞—Ç-–±–æ—Ç", icon=icon_svg('robot')):
    with ui.layout_columns(col_widths=(4, 8)):
        # –õ–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞: –§–∏–ª—å—Ç—Ä—ã –¥–ª—è —á–∞—Ç-–±–æ—Ç–∞
        with ui.card(full_screen=False):
            ui.card_header("üîé –§–∏–ª—å—Ç—Ä—ã –¥–ª—è —á–∞—Ç-–±–æ—Ç–∞")
            ui.input_password("chat_token", "API-–¢–æ–∫–µ–Ω —Å–µ—Ä–≤–∏—Å–∞:",
                              width='400px', placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–æ–∫–µ–Ω")
            ui.input_selectize("chat_model", "–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å:",
                               choices=[], width='400px')
            ui.input_selectize("base_url", "–ë–∞–∑–æ–≤—ã–π URL-–∞–¥—Ä–µ—Å —Å–µ—Ä–≤–∏—Å–∞:",
                               choices=["https://bothub.chat/api/v2/openai/v1",
                                        "https://api.deepseek.com", "https://openrouter.ai/api/v1"],
                               selected='https://openrouter.ai/api/v1', width='400px')
            ui.input_slider("temp", "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:", min=0,
                            max=1.5, value=0, step=0.1, width='400px')
            ui.hr()
            ui.input_slider("sample_size", "–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö:",
                            min=100, max=2000, value=400, step=100, width='400px')
            ui.input_action_button(
                "process_data", "–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ", width="400px")

        # –ü—Ä–∞–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞: –ß–∞—Ç-–±–æ—Ç
        with ui.card(full_screen=True):
            ui.card_header("ü§ñ –ß–∞—Ç-–±–æ—Ç")
            welcome = ui.markdown("Hi!")
            chat = ui.Chat(id="chat", messages=[welcome])
            chat.ui(placeholder='–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å...', width='min(850px, 100%)')

            @chat.on_user_submit
            async def process_chat():
                user_message = chat.user_input()
                if user_message == "–û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç":
                    await chat.clear_messages()
                    await chat.append_message_stream('–ß–∞—Ç –æ—á–∏—â–µ–Ω ‚úÖ')
                    return

                # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏–∑ —Ñ–∞–π–ª–∞, –ø—É—Ç—å —Å—Ç—Ä–æ–∏–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ temp_dir
                try:
                    build_vector_store()
                    vector_store_file = temp_dir / \
                        f"vector_store_{input.sample_size()}.pkl"
                    if not vector_store_file.exists():
                        await chat.append_message("–î–∞–Ω–Ω—ã–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É '–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ'.")
                        return
                except Exception as e:
                    await chat.append_message(f'–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ: {e}')
                    return

                try:
                    with open(vector_store_file, "rb") as f:
                        ensemble = pickle.load(f)
                except Exception as e:
                    await chat.append_message(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: {e}")
                    return

                model = input.chat_model()
                temperature = input.temp()
                base_url = input.base_url()
                api_key = input.chat_token() or None

                try:
                    llm = ChatOpenAI(model_name=model,
                                     temperature=temperature,
                                     max_tokens=6000,
                                     base_url=base_url,
                                     openai_api_key=api_key)
                    llm_chain = (
                        {"context": ensemble | format_docs,
                         "question": RunnablePassthrough()}
                        | prompt
                        | llm
                        | StrOutputParser()
                    )
                    response = llm_chain.invoke(user_message)
                    await chat.append_message_stream(response)
                except Exception as e:
                    await chat.append_message(f'–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}')
